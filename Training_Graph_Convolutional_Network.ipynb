{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from skimage import io\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import os\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "from scipy.spatial import distance_matrix\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from stellargraph.layer.gcn import GraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanaz\\AppData\\Local\\Temp/ipykernel_7124/79560190.py:39: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = slic(image , n_segments = 200, compactness = 10, sigma = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key 73\n",
      "(73, 6)\n",
      "(73, 3)\n",
      "Adj (73, 73)\n",
      "Time:  0.00010772099994937889\n"
     ]
    }
   ],
   "source": [
    "label_matrix2 = []\n",
    "DATADIR = \"dataset\"\n",
    "#CATEGORIES = [\"Class1\",\"Class2\",\"Class3\"]\n",
    "CATEGORIES = [\"Class1\"]\n",
    "Mean_matrix = []\n",
    "Mean_index_matrix = []\n",
    "b = 0\n",
    "a = 1\n",
    "while b < a:\n",
    "    for category in CATEGORIES:\n",
    "        labels = [0,0,0]\n",
    "        if category == \"Class1\":\n",
    "            label = \"Class1\"\n",
    "            labels[0] = 1\n",
    "        elif category == \"Class2\":\n",
    "            label = \"Class2\"\n",
    "            labels[1] = 1\n",
    "        else:\n",
    "            label = \"Class3\"\n",
    "            labels[2] = 1\n",
    "\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        clss_name, _ = os.path.splitext(category)\n",
    "        for img in os.listdir(path): \n",
    "\n",
    "            mean_pixl = []\n",
    "            mtrx = []\n",
    "            name, _ = os.path.splitext(img)          \n",
    "            image= img_as_float(imread(os.path.join(path,img)))            \n",
    "            X = image.shape[0]\n",
    "            Y = image.shape[1]\n",
    "            segments = slic(image , n_segments = 200, compactness = 10, sigma = 1)        \n",
    "\n",
    "    ##########################################\n",
    "\n",
    "            keys = np.unique(segments)\n",
    "            N = len(keys)\n",
    "            a = N\n",
    "            features =  np.zeros((N,6))\n",
    "            label_matrix = np.zeros((N,3))\n",
    "            print(\"key\",len(keys))\n",
    "            for key in keys:\n",
    "                result = np.where(segments == key)\n",
    "                listOfIndices= list(zip(result[0], result[1]))\n",
    "                Mean_index = list(np.mean(listOfIndices,axis=0))\n",
    "                Mean_index_matrix.append(Mean_index)\n",
    "                RGB_Mean = np.mean(image[np.where(segments == key)],axis=0)\n",
    "                RGB_Std = np.std(image[np.where(segments == key)],axis=0)\n",
    "                feature = [RGB_Mean[0],RGB_Mean[1],RGB_Mean[2],RGB_Std[0],RGB_Std[1],RGB_Std[2]]\n",
    "                mean_pixl.append(Mean_index)\n",
    "                label_matrix2.append(label)\n",
    "\n",
    "                label_matrix[b]= labels\n",
    "                features [b] = feature\n",
    "                b += 1\n",
    "                \n",
    "F = len(features[0])\n",
    "print(features.shape)\n",
    "print(label_matrix.shape)\n",
    " \n",
    "dist_mat = distance_matrix(Mean_index_matrix, Mean_index_matrix, p=2)\n",
    "\n",
    "\n",
    "dist_mat = distance_matrix(Mean_index_matrix, Mean_index_matrix, p=2)\n",
    "matrix = []\n",
    "for i in range(0,dist_mat.shape[0]):\n",
    "    indx = []\n",
    "    sr = sorted(dist_mat[i])\n",
    "    for j in range(0,3):\n",
    "        inx = np.where(dist_mat[i]==sr[j])\n",
    "        \n",
    "        r = inx[0]\n",
    "        \n",
    "        indx.extend(r)\n",
    "\n",
    "    matrix.append(indx)\n",
    "    \n",
    "matrix_new2 = []\n",
    "for x in matrix:\n",
    "    y = list(np.unique(x))\n",
    "    matrix_new2.append(y)\n",
    "\n",
    "mx = len(matrix_new2)\n",
    "Adj = np.zeros((mx,mx))\n",
    "l = len(matrix)\n",
    "for i in range(0,l):\n",
    "    matrix2 = matrix_new2[i]\n",
    "    for j in range(0,len(matrix2)):\n",
    "        matrix2_m = matrix2[j]\n",
    "        Adj[i,matrix2_m] = 1\n",
    "print(\"Adj\",np.array(Adj).shape)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n"
     ]
    }
   ],
   "source": [
    "def limit_data(label_matrix2,limit=20,val_num=30,test_num=23):\n",
    "    '''\n",
    "    Get the index of train, validation, and test data\n",
    "    '''\n",
    "    label_counter = dict((l, 0) for l in label_matrix2)\n",
    "    train_idx = []\n",
    "\n",
    "    for i in range(len(label_matrix2)):\n",
    "        label = label_matrix2[i]\n",
    "        if label_counter[label]<limit:\n",
    "            #add the example to the training data\n",
    "            train_idx.append(i)\n",
    "            label_counter[label]+=1\n",
    "        \n",
    "        #exit the loop once we found 20 examples for each class\n",
    "        if all(count == limit for count in label_counter.values()):\n",
    "            break\n",
    "    \n",
    "    #get the indices that do not go to traning data\n",
    "    rest_idx = [x for x in range(len(label_matrix2)) if x not in train_idx]\n",
    "    val_idx = rest_idx[:val_num]\n",
    "    test_idx = rest_idx[val_num:(val_num+test_num)]\n",
    "    return train_idx, val_idx,test_idx\n",
    "\n",
    "train_idx,val_idx,test_idx = limit_data(label_matrix2)\n",
    "\n",
    "#set the mask\n",
    "train_mask = np.zeros((N,),dtype=bool)\n",
    "train_mask[train_idx] = True\n",
    "\n",
    "val_mask = np.zeros((N,),dtype=bool)\n",
    "val_mask[val_idx] = True\n",
    "\n",
    "test_mask = np.zeros((N,),dtype=bool)\n",
    "test_mask[test_idx] = True\n",
    "print(val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 73, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 73, 6)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 73, 73)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution (GraphConvolu (None, 73, 16)       96          dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 73, 16)       0           graph_convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 73, 3)        48          dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(1, 73)\n",
      "(1, 73, 3)\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4108 - acc: 0.3500 - val_loss: 0.1395 - val_acc: 1.0000\n",
      "Epoch 2/200\n",
      "WARNING:tensorflow:From c:\\users\\sanaz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4111 - acc: 0.4000 - val_loss: 0.0726 - val_acc: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1041 - acc: 0.9000 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1282 - acc: 0.7000 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0690 - acc: 0.9500 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0837 - acc: 0.9500 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0916 - acc: 0.9000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0314 - acc: 0.9500 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0301 - acc: 0.9500 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 159ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3e8bffc910>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = 16          \n",
    "dropout = 0.5           \n",
    "l2_reg = 5e-4           \n",
    "learning_rate = 1e-2    \n",
    "epochs = 200           \n",
    "es_patience = 10       \n",
    "\n",
    "X_in = Input(shape=(N,F ))\n",
    "fltr_in = Input((N,N ))\n",
    "\n",
    "dropout_1 = Dropout(dropout)(X_in)\n",
    "graph_conv_1 = GraphConvolution(channels,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([dropout_1, fltr_in])\n",
    "\n",
    "dropout_2 = Dropout(dropout)(graph_conv_1)\n",
    "num_classes = 3\n",
    "graph_conv_2 = GraphConvolution(num_classes,\n",
    "                         activation='softmax',\n",
    "                         use_bias=False)([dropout_2, fltr_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_2)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "tbCallBack_GCN = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./Tensorboard_GCN_cora',\n",
    ")\n",
    "callback_GCN = [tbCallBack_GCN]\n",
    "val_mask = np.expand_dims(val_mask, 0)\n",
    "print(val_mask.shape)\n",
    "train_mask = np.expand_dims(train_mask, 0)\n",
    "\n",
    "label_matrix= np.expand_dims(label_matrix, 0)\n",
    "features= np.expand_dims(features, 0)\n",
    "Adj= np.expand_dims(Adj, 0)\n",
    "print(np.array(label_matrix).shape)\n",
    "validation_data = ([features, Adj], label_matrix, val_mask)\n",
    "model.fit([features, Adj],\n",
    "          label_matrix,\n",
    "          sample_weight=train_mask,\n",
    "          epochs=epochs,\n",
    "          batch_size=7,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,\n",
    "          callbacks=[\n",
    "              EarlyStopping(patience=es_patience,  restore_best_weights=True),\n",
    "              tbCallBack_GCN\n",
    "          ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
